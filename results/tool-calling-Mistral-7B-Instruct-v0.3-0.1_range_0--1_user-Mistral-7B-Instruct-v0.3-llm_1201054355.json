[
  {
    "task_id": 0,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 0,
    "records": {}
  },
  {
    "task_id": 1,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 1,
    "records": {}
  },
  {
    "task_id": 2,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 2,
    "records": {}
  },
  {
    "task_id": 3,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 3,
    "records": {}
  },
  {
    "task_id": 4,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 4,
    "records": {}
  },
  {
    "task_id": 5,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 5,
    "records": {}
  },
  {
    "task_id": 6,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 6,
    "records": {}
  },
  {
    "task_id": 7,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 7,
    "records": {}
  },
  {
    "task_id": 8,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 8,
    "records": {}
  },
  {
    "task_id": 9,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 9,
    "records": {}
  },
  {
    "task_id": 10,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 10,
    "records": {}
  },
  {
    "task_id": 11,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 11,
    "records": {}
  },
  {
    "task_id": 12,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 12,
    "records": {}
  },
  {
    "task_id": 13,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 13,
    "records": {}
  },
  {
    "task_id": 14,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 14,
    "records": {}
  },
  {
    "task_id": 15,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 15,
    "records": {}
  },
  {
    "task_id": 16,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 16,
    "records": {}
  },
  {
    "task_id": 17,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 17,
    "records": {}
  },
  {
    "task_id": 18,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 18,
    "records": {}
  },
  {
    "task_id": 19,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 19,
    "records": {}
  },
  {
    "task_id": 20,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 20,
    "records": {}
  },
  {
    "task_id": 21,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 21,
    "records": {}
  },
  {
    "task_id": 22,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 22,
    "records": {}
  },
  {
    "task_id": 23,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 23,
    "records": {}
  },
  {
    "task_id": 24,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 24,
    "records": {}
  },
  {
    "task_id": 25,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 25,
    "records": {}
  },
  {
    "task_id": 26,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 26,
    "records": {}
  },
  {
    "task_id": 27,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 27,
    "records": {}
  },
  {
    "task_id": 28,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 28,
    "records": {}
  },
  {
    "task_id": 29,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 29,
    "records": {}
  },
  {
    "task_id": 30,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 30,
    "records": {}
  },
  {
    "task_id": 31,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 31,
    "records": {}
  },
  {
    "task_id": 32,
    "reward": 0.0,
    "info": {
      "error": "litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set",
      "traceback": "Traceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 745, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 673, in completion\n    ) = self.make_sync_openai_chat_completion_request(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\", line 237, in sync_wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 489, in make_sync_openai_chat_completion_request\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 471, in make_sync_openai_chat_completion_request\n    raw_response = openai_client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2160, in completion\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 2132, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/llms/openai/openai.py\", line 756, in completion\n    raise OpenAIError(\nlitellm.llms.openai.common_utils.OpenAIError: Error code: 400 - {'error': {'message': '\"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set', 'type': 'BadRequestError', 'param': None, 'code': 400}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/run.py\", line 120, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 44, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/home/madhav/ext-madhav/tau-bench/tau_bench/trapi_infer.py\", line 137, in completion\n    res = _litellm_completion(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1381, in wrapper\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/utils.py\", line 1250, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/main.py\", line 3774, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2328, in exception_type\n    raise e\n  File \"/home/madhav/miniconda3/envs/tau/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 473, in exception_type\n    raise BadRequestError(\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - \"auto\" tool choice requires --enable-auto-tool-choice and --tool-call-parser to be set\n"
    },
    "traj": [],
    "trial": 32,
    "records": {}
  }
]